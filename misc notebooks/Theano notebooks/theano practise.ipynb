{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook i am going to practise theano of alex redford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano \n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=T.scalar()\n",
    "Y=T.scalar()\n",
    "out=X*Y\n",
    "multiply=theano.function(inputs=[X,Y],outputs=out)\n",
    "multiply(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above i did a symbolic computation, First i defined all the mathematical symbols then, for final computation i have to explicitly provide value to the symbolic graph for the computation to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linear regression\n",
    "import numpy as np\n",
    "\n",
    "trX=np.linspace(-1,1,100)\n",
    "trY=2*trX+np.random.rand(*trX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1760269969353101"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#data symbols\n",
    "X=T.scalar()\n",
    "Y=T.scalar()\n",
    "\n",
    "#prediction\n",
    "def model(X,w):\n",
    "    return X*w\n",
    "\n",
    "\n",
    "w=theano.shared(np.asarray(0.,dtype=theano.config.floatX))\n",
    "w = theano.shared(np.asarray(0., dtype=theano.config.floatX))\n",
    "y = model(X, w)\n",
    "\n",
    "cost = T.mean(T.sqr(y - Y))\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "updates = [[w, w - gradient * 0.01]]\n",
    "\n",
    "# w = theano.shared(np.asarray(0., dtype=theano.config.floatX))\n",
    "# y = model(X, w)\n",
    "\n",
    "# cost = T.mean(T.sqr(y - Y))\n",
    "# gradient = T.grad(cost=cost, wrt=w)\n",
    "# updates = [[w, w - gradient * 0.01]]\n",
    "\n",
    "train=theano.function(inputs=[X,Y],outputs=cost,updates=updates,allow_input_downcast=True)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    for x,y in zip(trX,trY):\n",
    "#     train(trX,trY)\n",
    "        train(x,y)\n",
    "\n",
    "# train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "# for i in range(100):\n",
    "#     for x, y in zip(trX, trY):\n",
    "#         train(x, y)\n",
    "        \n",
    "w.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print trX.shape\n",
    "print trY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.05808223088\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "\n",
    "trX = np.linspace(-1, 1, 101)\n",
    "trY = 2 * trX + np.random.randn(*trX.shape) * 0.33\n",
    "\n",
    "X = T.scalar()\n",
    "Y = T.scalar()\n",
    "\n",
    "def model(X, w):\n",
    "    return X * w\n",
    "\n",
    "w = theano.shared(np.asarray(0., dtype=theano.config.floatX))\n",
    "y = model(X, w)\n",
    "\n",
    "cost = T.mean(T.sqr(y - Y))\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "updates = [[w, w - gradient * 0.01]]\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "for i in range(100):\n",
    "    for x, y in zip(trX, trY):\n",
    "        train(x, y)\n",
    "        \n",
    "print w.get_value() #something around 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now i am going to do logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits=datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images', 'data', 'target_names', 'DESCR', 'target']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data=(digits['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_val=(digits['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test=train_test_split(input_data,output_val,test_size=0.20)\n",
    "x_train,y_train,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_onehot_encoding(y):\n",
    "    final=np.zeros((y.shape[0],10))\n",
    "    for i in range(10):\n",
    "        final[:,i]=((y==i)+0)\n",
    "    return final\n",
    "\n",
    "y_ohe=create_onehot_encoding(output_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797, 10)\n"
     ]
    }
   ],
   "source": [
    "print input_data.shape\n",
    "print y_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#splitting the data in train,validation and test set\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(input_data,y_ohe,test_size=0.20)\n",
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'W1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-4f4950979ca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mbest_prediction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#initializing the data symbols\n",
    "\n",
    "X=T.fmatrix()\n",
    "y=T.fmatrix()\n",
    "\n",
    "#initializing the shared weight variable w\n",
    "\n",
    "def floatX(x):\n",
    "    return np.asarray(x,dtype=theano.config.floatX)\n",
    "\n",
    "def init_weight(shape):\n",
    "    return theano.shared(floatX(np.random.rand(*shape)))\n",
    "\n",
    "\n",
    "w=init_weight((64,10))\n",
    "b=theano.shared(np.zeros())\n",
    "\n",
    "def model(X,w):\n",
    "    return T.nnet.softmax(T.dot(X,w))\n",
    "\n",
    "\n",
    "py_x=model(X,w)\n",
    "\n",
    "cost=T.mean(T.nnet.categorical_crossentropy(py_x,y))\n",
    "\n",
    "gradient=T.grad(cost=cost,wrt=w)\n",
    "\n",
    "update=[[w,w-gradient*0.05]]\n",
    "\n",
    "pred=T.argmax(py_x,axis=1)\n",
    "\n",
    "train=theano.function(inputs=[X,y],outputs=[cost],updates=update,allow_input_downcast=True)\n",
    "\n",
    "prediction=theano.function(inputs=[X],outputs=[pred],allow_input_downcast=True)\n",
    "\n",
    "best_prediction=0\n",
    "best_param={}\n",
    "best_param[\"W1\"]=100\n",
    "best_param[\"b1\"]=100\n",
    "best_param[\"W2\"]=100\n",
    "best_param[\"b2\"]=100\n",
    "\n",
    "for i in range(100):\n",
    "#     cost=train(X_train,y_train)\n",
    "#     #print prediction(X_val)\n",
    "    \n",
    "#     temp_prediction=np.asarray(prediction(X_val))\n",
    "#     temp_prediction=temp_prediction.flatten()\n",
    "#     temp_prediction=create_onehot_encoding(np.asarray(temp_prediction))\n",
    "#     accuracy=np.sum((temp_prediction+y_val)==2)\n",
    "#     print accuracy\n",
    "    if accuracy>best_prediction:\n",
    "        best_param[\"W1\"]=W1.get_value()\n",
    "        best_param[\"b1\"]=b1.get_value()\n",
    "        best_param[\"W2\"]=W2.get_value()\n",
    "        best_param[\"b2\"]=b2.get_value()\n",
    "\n",
    "#py_x.eval(inputs_to_values={'X':trX,'w':w})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.43639382892\n",
      "4.44926959776\n",
      "12.1200157031\n",
      "16.9076152996\n",
      "18.6603154814\n",
      "16.943597133\n",
      "13.8915430829\n",
      "14.3447523898\n",
      "13.7390465083\n",
      "12.2701008277\n",
      "8.34665250889\n",
      "7.24339183755\n",
      "7.87754949837\n",
      "6.84934957912\n",
      "3.34861562509\n",
      "1.31109820565\n",
      "0.953513228743\n",
      "0.498283438371\n",
      "0.368702164592\n",
      "0.282142590359\n",
      "0.243058867154\n",
      "0.220544948379\n",
      "0.207033578406\n",
      "0.196420116628\n",
      "0.187252412235\n",
      "0.179002695068\n",
      "0.171471642908\n",
      "0.164557786409\n",
      "0.158197880759\n",
      "0.152346289756\n",
      "0.146966753852\n",
      "0.142027788889\n",
      "0.137498697886\n",
      "0.133347654665\n",
      "0.1295410174\n",
      "0.126044319519\n",
      "0.122823703373\n",
      "0.119847355204\n",
      "0.11708642711\n",
      "0.11451545206\n",
      "0.112112345092\n",
      "0.109858157248\n",
      "0.107736712192\n",
      "0.105734212597\n",
      "0.103838866169\n",
      "0.102040553354\n",
      "0.10033054412\n",
      "0.0987012620779\n",
      "0.0971460909106\n",
      "0.0956592165711\n",
      "0.0942354990321\n",
      "0.0928703679328\n",
      "0.0915597374447\n",
      "0.0902999364989\n",
      "0.0890876513196\n",
      "0.087919877828\n",
      "0.0867938820078\n",
      "0.085707166718\n",
      "0.0846574437595\n",
      "0.08364261024\n",
      "0.0826607284722\n",
      "0.0817100087877\n",
      "0.0807887947629\n",
      "0.0798955504473\n",
      "0.0790288492557\n",
      "0.0781873642499\n",
      "0.0773698595804\n",
      "0.0765751829032\n",
      "0.0758022586178\n",
      "0.0750500818012\n",
      "0.0743177127359\n",
      "0.0736042719493\n",
      "0.0729089356947\n",
      "0.0722309318206\n",
      "0.071569535981\n",
      "0.0709240681508\n",
      "0.0702938894132\n",
      "0.069678398995\n",
      "0.069077031526\n",
      "0.0684892545036\n",
      "0.0679145659461\n",
      "0.0673524922196\n",
      "0.066802586025\n",
      "0.0662644245329\n",
      "0.0657376076561\n",
      "0.0652217564482\n",
      "0.0647165116206\n",
      "0.0642215321676\n",
      "0.0637364940935\n",
      "0.0632610892322\n",
      "0.0627950241545\n",
      "0.0623380191556\n",
      "0.061889807317\n",
      "0.061450133639\n",
      "0.0610187542358\n",
      "0.0605954355929\n",
      "0.0601799538783\n",
      "0.0597720943068\n",
      "0.0593716505526\n",
      "0.0589784242071\n"
     ]
    }
   ],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.randn(*shape) * 0.01))\n",
    "\n",
    "def model(X, w):\n",
    "    return T.nnet.softmax(T.dot(X, w))\n",
    "\n",
    "\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "w = init_weights((64, 10))\n",
    "\n",
    "py_x = model(X, w)\n",
    "y_pred = T.argmax(py_x, axis=1)\n",
    "\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(py_x, Y))\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "update = [[w, w - gradient * 0.05]]\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "for i in range(100):\n",
    "    cost=train(X_train,y_train)\n",
    "    print cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learnings:\n",
    "\n",
    "theano is very particular about the types used in the variable of the graph. For example the shared variables in theano has to be defined with dtype of theano.config.floatX.\n",
    "\n",
    "\n",
    "Also some data matrices are stored as float32 and some as float64, now operations between data types of two different float bits is not possible. So to overcome this, theano.function has argument allow_input_downcast=True, when i use this arg then theano explicitly downcasts the 64 bit float to a 32 bit float. Another way around this problem is to convert the float 64 to float 32 and then pass the two variables in theano.function\n",
    "\n",
    "Above X was float64 and y was float 32 so either I explicitly make the two same and then pass to the function or i can use allow_input_downcast=True\n",
    "\n",
    "\n",
    "\n",
    "First i have to create a container for the input data, in the code above X and y symbolic variable for the data. for any given problem the input i have are the X and the y varaibles so the final train function has X and y as the input, we also add the shared parameter varaible w. All the other intermediate values are calculated in a symbolic manner , from the symbolic expression of the graph.\n",
    "\n",
    "\n",
    "\n",
    "the shared variable in theano has to have data type of theno.config.floatX. now in the code above i have made an array and then forcibly converted the array to the desired data type. it is very important to note that the shared variable w in theno needs to have data type of theano.config.floatX\n",
    "\n",
    "\n",
    "the update symbolic varaible is a list of list.\n",
    "\n",
    "the theano.function takes updates as an argument where i can pass on the update equation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for taking the dot product of two symbolic variable in theano, i have to use T.dot() and not np.dot() function\n",
    "\n",
    "\n",
    "The variable intialization for data storage, ie T.fmatrix() means that i am having a float matrix. so when the input and output have to be treated as floats then i am going to use the T.fmatrix() function. Also note that theano is very very particulare with data types and type checkings.\n",
    "\n",
    "\n",
    "Cost should always be a scalar hence i need to use T.mean() to reduce a vector cost to a scalar cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n",
      "0.0888888888889\n"
     ]
    }
   ],
   "source": [
    "#now i am attempting a generic neural network in theano\n",
    "\n",
    "#cerating symbolic variables for the data container\n",
    "\n",
    "X=T.fmatrix()\n",
    "y=T.fmatrix()\n",
    "\n",
    "\n",
    "\n",
    "#the network architecture is going to be 64 x 100 x 10\n",
    "\n",
    "input_dim=64\n",
    "hidden_dim=100\n",
    "output_dim=10\n",
    "\n",
    "def floatX(x):\n",
    "    return np.asarray(x,dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape):\n",
    "    return theano.shared(floatX(np.random.rand(*shape)))\n",
    "\n",
    "def init_bias(shape):\n",
    "    return theano.shared(np.asarray(np.zeros(shape),dtype=theano.config.floatX))\n",
    "\n",
    "\n",
    "W1=init_weights((64,100))\n",
    "b1=init_bias(100)\n",
    "\n",
    "W2=init_weights((100,10))\n",
    "b2=init_bias(10)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+T.exp(-x))\n",
    "\n",
    "def model(X,W1,b1,W2,b2):\n",
    "    a1=T.dot(X,W1)+b1\n",
    "    z1=sigmoid(a1)\n",
    "    \n",
    "    a2=T.dot(z1,W2)+b2\n",
    "    z2=T.nnet.softmax(a2)\n",
    "    \n",
    "    return z2\n",
    "\n",
    "y_pred=model(X,W1,b1,W2,b2)\n",
    "\n",
    "cost=T.mean(T.nnet.categorical_crossentropy(y_pred,y))\n",
    "\n",
    "\n",
    "dW1=T.grad(cost=cost,wrt=W1)\n",
    "dW2=T.grad(cost=cost,wrt=W2)\n",
    "\n",
    "db1=T.grad(cost=cost,wrt=b1)\n",
    "db2=T.grad(cost=cost,wrt=b2)\n",
    "\n",
    "\n",
    "\n",
    "update=[[W1,W1-0.01*dW1],[b1,b1-0.01*db1],[W2,W2-0.01*dW2],[b2,b2-0.01*db2]]\n",
    "\n",
    "pred=T.argmax(y_pred,axis=1)\n",
    "\n",
    "train=theano.function(inputs=[X,y],outputs=cost,updates=update,allow_input_downcast=True)\n",
    "prediction=theano.function(inputs=[X],outputs=pred,allow_input_downcast=True)\n",
    "\n",
    "best_accuracy=0\n",
    "\n",
    "best_param={}\n",
    "\n",
    "for i in range(100):\n",
    "    cost=train(X_train,y_train)\n",
    "    \n",
    "    temp_prediction=np.asarray(prediction(X_val))\n",
    "    temp_prediction=temp_prediction.flatten()\n",
    "    temp_prediction=create_onehot_encoding(np.asarray(temp_prediction))\n",
    "    accuracy=1.0*((np.sum((temp_prediction+y_val)==2)))/float(y_val.shape[0])\n",
    "    print accuracy\n",
    "    if accuracy>best_accuracy:\n",
    "        best_accuracy=accuracy\n",
    "        best_param[\"W1\"]=W1.get_value()\n",
    "        best_param[\"b1\"]=b1.get_value()\n",
    "        best_param[\"W2\"]=W2.get_value()\n",
    "        best_param[\"b2\"]=b2.get_value()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11944444444444445"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43/float(360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
