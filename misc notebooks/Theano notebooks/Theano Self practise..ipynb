{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in this notebook i am going to write the common parameteric machine learning methods. I will start off with regression,logistic regression,neural network,convolution neural network, finally RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating data for linear regression\n",
    "np.random.seed(123)\n",
    "input_val=np.random.uniform(1,100,100)\n",
    "output=10*input_val+np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in theano we define graphs of computation what this means is that i define mathematical expression that do the computation. for evaluation of the mathematical expression i use the eval method of the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n"
     ]
    }
   ],
   "source": [
    "X=T.vector(name=\"X\",dtype=None)\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above i have defined X as a theano vector, now when i print X then i get its name, there is no value attached with X. Such theano symbolic variables are called stateless, this means every time i want to evaluate X or any other symbolic expression.Then i will explicitly have to pass the input value for the expression. This is done via the eval method of the theano expression. The input to the eval method is the actual values for the variables present in the theano symbolic expression. The input is passed in as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.eval({X:[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another type of theano variable is the shared variable, the shared variable have states. This means the actual value of the variables are stored in the memory. So this shared varaibles can be accessed by all the functions in the theano environment and also these variables can be updated by all the funcitons. One way to think about the shared variables is to think of them as global variables whose values are preserved in the memory. When i intialize the shared variable then i have to initialize the value of the shared variable also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.75160653  0.97055618]\n",
      " [ 0.97250295  0.98475057]\n",
      " [ 0.2125787   0.87757768]\n",
      " [ 0.37654479  0.26357592]\n",
      " [ 0.54958269  0.76609178]\n",
      " [ 0.3589441   0.88913325]\n",
      " [ 0.58314388  0.87209826]\n",
      " [ 0.13354264  0.90632715]\n",
      " [ 0.66870518  0.78033132]\n",
      " [ 0.81665128  0.27353627]]\n"
     ]
    }
   ],
   "source": [
    "W1=theano.shared(np.random.rand(10,2),name=\"W1\")\n",
    "\n",
    "\n",
    "#note i can print the W1 var without passing the arguments to the eval method.\n",
    "print W1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now this is all i need to do linear,logistic and neural network in thenao\n",
    "\n",
    "X=T.vector(name=\"X\",dtype=None)\n",
    "y=T.vector(name=\"y\",dtype=None)\n",
    "\n",
    "#since w has to be changed at each iteration hence initializing a shared variable w\n",
    "\n",
    "w=theano.shared(np.random.rand(1),name=\"w\")\n",
    "\n",
    "#prediction function\n",
    "\n",
    "#y_hat=np.multiply(w,X)\n",
    "y_hat=w*X\n",
    "\n",
    "pred=theano.function(inputs=[X],outputs=y_hat)\n",
    "\n",
    "cost=T.mean(T.sqr(y-y_hat))\n",
    "\n",
    "gradient=T.grad(cost=cost,wrt=w)\n",
    "\n",
    "updates=[[w,w-0.01*gradient]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do actual evaluation i can do it via two ways, the first way is to use the eval method. When I am using the eval method then i need to explicitly pass the input arg to the symbolic expression i want to evaluate. A much better way to do so is to use a theano.function. The input to the function is the list of actual input values, output is the symbolic variable i want to output. Once i have defined a theano.Function then i can use it just like any other python function syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.07400123,   5.48147468,   4.38444307,  10.38814067,\n",
       "        13.49957707,   8.01584192,  18.33444579,  12.85863106,\n",
       "         9.08581331,   7.44243893,   6.53688827,  13.67685397,\n",
       "         8.30201262,   1.29115199,   7.55210414,  13.84238044,\n",
       "         3.56363422,   3.43337026,  10.02244926,  10.02756016,\n",
       "        11.92552358,  15.90434044,  13.59184195,  11.49295965,\n",
       "        13.55461403,   6.16276469,   6.8812497 ,   4.41056585,\n",
       "         5.62163313,  11.86215225,   1.89116485,   8.21188088,\n",
       "         8.15936046,   9.32179171,   8.06624224,   5.96482028,\n",
       "         8.07588285,  16.71770435,  17.6571414 ,   9.4726242 ,\n",
       "        11.73219919,   2.32624539,   6.05778651,   7.86262859,\n",
       "        16.21663025,   4.82119738,   9.12471432,  18.4231808 ,\n",
       "         9.79918166,  11.52757992,   2.41895279,  15.47707691,\n",
       "        11.34560943,  10.27255388,   6.52922446,   5.81419399,\n",
       "         7.9032622 ,  12.79333281,  16.38589416,   9.63148874,\n",
       "        12.57153202,  11.02876384,  11.74978767,  12.67099313,\n",
       "        15.77316274,   1.72629981,  14.31768717,   4.69557748,\n",
       "         3.7807027 ,  10.77934454,   1.95791754,  16.56852313,\n",
       "        11.793187  ,  13.57261746,   0.48535006,  11.18595688,\n",
       "        10.48936249,   3.12820894,   3.01923961,  13.05661431,\n",
       "         6.08518912,  12.99075614,  10.44491821,   7.38383947,\n",
       "        17.30506607,  15.76072025,   6.79999931,   0.99349714,\n",
       "         5.826171  ,   7.55472102,  13.23108913,  18.6044907 ,\n",
       "         6.7725642 ,  14.29668522,  11.16273571,  12.98578802,\n",
       "         2.9832862 ,   7.56749972,   4.6435739 ,   6.54203219])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_val1=input_val.reshape((100,1))\n",
    "#w.get_value()*input_val1\n",
    "pred(input_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=theano.function(inputs=[X,y],outputs=cost,updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Bad input argument to theano function with name \"<ipython-input-62-5a4bdbb92bfb>:1\"  at index 0(0-based)', 'Wrong number of dimensions: expected 1, got 0 with shape ().')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-e4019d880f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                         s.storage[0] = s.type.filter(arg, strict=s.strict,\n\u001b[0;32m--> 513\u001b[0;31m                                 allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise TypeError(\"Wrong number of dimensions: expected %s,\"\n\u001b[1;32m    168\u001b[0m                             \" got %s with shape %s.\" % (self.ndim, data.ndim,\n\u001b[0;32m--> 169\u001b[0;31m                                                         data.shape))\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Bad input argument to theano function with name \"<ipython-input-62-5a4bdbb92bfb>:1\"  at index 0(0-based)', 'Wrong number of dimensions: expected 1, got 0 with shape ().')"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    for a,b in zip(input_val,output):\n",
    "        train(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=T.scalar()\n",
    "y=T.scalar()\n",
    "\n",
    "def model(X,w):\n",
    "    return X*w\n",
    "\n",
    "w=theano.shared(np.asarray(0.0,dtype=theano.config.floatX))\n",
    "\n",
    "y_hat=model(X,w)\n",
    "\n",
    "cost=T.mean(T.sqr(y-y_hat))\n",
    "\n",
    "gradient=T.grad(cost=cost,wrt=w)\n",
    "\n",
    "updates=[[w,w-gradient*0.01]]\n",
    "\n",
    "train=theano.function(inputs=[X,y],outputs=cost,updates=updates)\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    for trX,trY in zip(input_val,output):\n",
    "        train(trX,trY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print w.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.02534637593\n"
     ]
    }
   ],
   "source": [
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "\n",
    "trX = np.linspace(-1, 1, 101)\n",
    "trY = 2 * trX + np.random.randn(*trX.shape) * 0.33\n",
    "\n",
    "X = T.scalar()\n",
    "Y = T.scalar()\n",
    "\n",
    "def model(X, w):\n",
    "    return X * w\n",
    "\n",
    "w = theano.shared(np.asarray(0., dtype=theano.config.floatX))\n",
    "y = model(X, w)\n",
    "\n",
    "cost = T.mean(T.sqr(y - Y))\n",
    "gradient = T.grad(cost=cost, wrt=w)\n",
    "updates = [[w, w - gradient * 0.01]]\n",
    "\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "for i in range(100):\n",
    "    for x, y in zip(trX, trY):\n",
    "        train(x, y)\n",
    "        \n",
    "print w.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print input_val.shape\n",
    "print output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19133572,  0.67690586,  0.21550545,  0.27802359,  0.74176042,\n",
       "        0.5597379 ,  0.33483641,  0.54298878,  0.6939847 ,  0.91213212,\n",
       "        0.58071321,  0.23268638,  0.74669763,  0.77776902,  0.20040131,\n",
       "        0.82057422,  0.46493485,  0.77976666,  0.23747822,  0.33258027,\n",
       "        0.95369712,  0.65781507,  0.77287783,  0.68837434,  0.20430412,\n",
       "        0.47068875,  0.80896387,  0.67503513,  0.00602789,  0.08740774,\n",
       "        0.34679472,  0.94436554,  0.49119048,  0.27017627,  0.36042372,\n",
       "        0.21065263,  0.42120006,  0.21803544,  0.84575251,  0.4562706 ,\n",
       "        0.27980202,  0.93289165,  0.31435135,  0.90971466,  0.04341809,\n",
       "        0.70711506,  0.48388904,  0.44422106,  0.03632334,  0.04068319,\n",
       "        0.33275362,  0.94711954,  0.61765998,  0.36887484,  0.61197704,\n",
       "        0.20613154,  0.16506644,  0.36181727,  0.86335335,  0.50940173,\n",
       "        0.29690152,  0.95025163,  0.81596609,  0.32297394,  0.97209825,\n",
       "        0.9873511 ,  0.40866013,  0.6559231 ,  0.4056532 ,  0.25734811,\n",
       "        0.08265268,  0.26361035,  0.27147985,  0.39863908,  0.18488603,\n",
       "        0.9538184 ,  0.10287989,  0.62520853,  0.44169739,  0.42351805,\n",
       "        0.37199178,  0.86831471,  0.28047698,  0.02057616,  0.91809702,\n",
       "        0.86448028,  0.27690179,  0.52348755,  0.1090882 ,  0.09342707,\n",
       "        0.83746611,  0.41026572,  0.66171654,  0.94320056,  0.24513059,\n",
       "        0.01315983,  0.02414841,  0.70938569,  0.92455188,  0.46733027])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better understanding of theano, I am going to implement the neural network as mentioned by denny britz. Once i am through the exact representation then i can move on with the linear and logit regression part of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=T.matrix(name=\"X\")\n",
    "y=T.vector(name=\"y\")\n",
    "\n",
    "#the hidden dimension size is 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating the shared variables for weights \n",
    "input_dim=1\n",
    "hidden_dim=100\n",
    "output_dim=1\n",
    "\n",
    "\n",
    "W1=theano.shared(np.random.randn(input_dim,hidden_dim),name=\"W1\")\n",
    "b1=theano.shared(np.zeros(hidden_dim),name=\"b1\")\n",
    "\n",
    "W2=theano.shared(np.random.randn(hidden_dim,output_dim),name=\"W2\")\n",
    "b2=theano.shared(np.zeros(output_dim),name=\"b2\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot find a common data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-e1818ea5d1ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#hidden layer computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mz1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot find a common data type."
     ]
    }
   ],
   "source": [
    "#forward propogation\n",
    "\n",
    "#hidden layer computation\n",
    "z1=np.dot(X,W1)+b1\n",
    "a1=T.tanh(z1)\n",
    "\n",
    "#output layer computation\n",
    "z2=np.dot(a1,W2)+b2\n",
    "y_hat=T.nnet.softmax(z2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
